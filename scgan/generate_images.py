from importlib import import_module
import pickle as pkl
import numpy as np
import cv2

from scgan.utils.data_utils import *
from scgan.utils.training_utils import ModelCheckpoint
from scgan.config import Config
import argparse
import matplotlib.pyplot as plt


class ImgGenerator:
    def __init__(self, checkpt_path, config, char_map_path):
        """
        :param checkpt_path: Path of the model checkpoint file to be used
        :param config: Config with all the parameters to be used
        """

        self.config = config
        with open(char_map_path, 'rb') as f:
            char_map = pkl.load(f)
        self.char_map = char_map['char_map'] if self.config.dataset == "Ru_Sber" else char_map


        # Model
        print(f'Model: {config.architecture}')
        model_type = import_module('scgan.models.ScrabbleGAN')
        create_model = getattr(model_type, 'create_model')
        self.model = create_model(self.config, self.char_map)
        # print(self.model, end='\n\n')
        self.model.to(self.config.device)
        self.model.eval()

        self.word_map = WordMap(self.char_map)

        # Load model weights
        self.model_checkpoint = ModelCheckpoint(config=self.config)
        self.model, _, _, _ = self.model_checkpoint.load(self.model, epoch=None, checkpoint_path=checkpt_path)

    def generate(self, random_num_imgs=5, word_list=None, z=None):
        """
        Returns images generated by the trained generator model

        :param random_num_imgs: Number of images to be randomly generated using lexicon (only valid if word_list=None)
        :param word_list: List of words for which images need to be generated
        :param z: Noise vector determining the style of the images to be generated (32 dimension vector)
        """

        if word_list is None:
            # Generate random images
            with torch.no_grad():
                self.model.forward_fake(z=None, b_size=random_num_imgs)
        else:
            encoded_words, _ = self.word_map.encode(word_list)
            with torch.no_grad():
                self.model.forward_fake(z=None, fake_y=encoded_words, b_size=len(word_list))

        word_labels_decoded = self.word_map.decode(self.model.fake_y.cpu().numpy())

        return self.model.fake_img.squeeze(1).cpu().numpy(), self.model.fake_y.cpu().numpy(), word_labels_decoded

class ImgGenerator_2:
    def __init__(self, checkpt_path, config, char_map_path, shrink_ratio=0.5,
        lexicon_paths=None, return_rgb=False):
        """
        :param checkpt_path: Path of the model checkpoint file to be used.
        :param config: Config with all the parameters to be used.
        :param char_map_path: Path to pkl-file with char_map dict.
        :param lexicon_paths: List of paths to lexicon txt. Default is None.
        :param shrink_ratio: The ratio of image resize by width (ScrabbleGAN by
            default generate too wide images.
        :return_rgb: Return RGB image.
        """
        self.return_rgb = return_rgb
        self.shrink_ratio = shrink_ratio
        self.config = config
        with open(char_map_path, 'rb') as f:
            char_map = pkl.load(f)
        self.char_map = char_map['char_map']
        print(f'Model: {config.architecture}')
        model_type = import_module('scgan.models.' + self.config.architecture)
        create_model = getattr(model_type, 'create_model')
        self.model = create_model(self.config, self.char_map, lexicon_paths)
        self.model.to(self.config.device)
        self.model.eval()
        # Load model weights
        self.model_checkpoint = ModelCheckpoint(config=self.config)
        # TODO: хардкод 354 эпох
        self.model, _, _, _ = self.model_checkpoint.load(self.model, checkpoint_path=checkpt_path, epoch=31)

    def _shrink_images(self, images):
        """Resize image by width by shrink_ratio."""
        resized_images = []
        for img in images:
            h, w = img.shape[:2]
            resized_images.append(
                cv2.resize(img, (int(w * self.shrink_ratio), h), cv2.INTER_AREA)
            )
        return resized_images

    def _bgr2rgb(self, images):
        """Convert images to BGR."""
        rgb_images = []
        for img in images:
            rgb_images.append(
                cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            )
        return rgb_images

    def _renormalize_images(self, generated_imgs):
        """Renormalize generator outputs and return list of images."""
        images = []
        for img in generated_imgs:
            normalized_img = ((img + 1) * 255 / 2).astype(np.uint8)
            normalized_img = np.moveaxis(normalized_img, 0, -1)
            images.append(normalized_img)
        return images

    def _preprocess_words(self, word_list):
        """Preprocess input texts: remove out of vocabulary chars."""
        new_word_list = []
        for word in word_list:
            new_word = ''
            for char in word:
                if char in self.char_map:
                    new_word += char
                elif char.lower() in self.char_map:
                    new_word += char.lower()

            if len(new_word) == 0:
                new_word = ' '
            new_word_list.append(new_word)
        return new_word_list

    def generate(self, random_num_imgs=5, word_list=None, z=None):
        """
        Returns images generated by the trained generator model
        :param random_num_imgs: Number of images to be randomly generated using lexicon (only valid if word_list=None)
        :param word_list: List of words for which images need to be generated
        :param z: Noise vector determining the style of the images to be generated (32 dimension vector)
        """
        print(f"word_list: {word_list}")
        
        if word_list is None:
            b_size = random_num_imgs
        else:
            word_list = self._preprocess_words(word_list)
            b_size = len(word_list)

        print(f"word_list after preproc: {word_list}")
        with torch.no_grad():
            self.model.forward_fake(z=z, fake_y=word_list, b_size=b_size)

        # тут уже сильно разное
        # print(f"self.model.fake_img: {self.model.fake_img}")
        images = self._renormalize_images(
            self.model.fake_img.squeeze(1).cpu().numpy())
        images = self._shrink_images(images)
        if self.return_rgb:
            images = self._bgr2rgb(images)
        return images, self.model.fake_y_decoded
        
        
        if self.return_rgb:
            images = self._bgr2rgb(images)
        return images, self.model.fake_y_decoded



if __name__ == "__main__":
    # Construct the argument parse and parse the arguments
    ap = argparse.ArgumentParser()
    ap.add_argument("-c", "--checkpt_path", required=True, type=str,
                    help="Path of the model checkpoint file to be used")
    ap.add_argument("-m", "--char_map_path", required=True, type=str,
                    help="Path of the file with character mapping to be used")
    ap.add_argument("-n", "--num_imgs", required=False, type=int,
                    help="number of sample points")
    ap.add_argument("-w", "--word_list", required=False, nargs='+', default=[],
                    help="words for which images need to be generated")
    args = vars(ap.parse_args())
    checkpoint_path = args['checkpt_path']
    char_map_path = args['char_map_path']
    num_imgs = args['num_imgs'] if args['num_imgs'] is not None else 5
    word_list = args['word_list'] if len(args['word_list']) > 0 else None

    with open(f'{char_map_path}', 'rb') as f:
        char_map = pkl.load(f)

    config = Config
    generator = ImgGenerator(checkpt_path=checkpoint_path, config=config, char_map=char_map)
    generated_imgs, _, word_labels = generator.generate(num_imgs, word_list)

    for label, img in zip(word_labels, generated_imgs):
        plt.imshow(img, cmap='gray')
        plt.title(label)
        plt.show()


